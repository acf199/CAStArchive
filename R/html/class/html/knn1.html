<html><head><title>R: 1-nearest neighbour classification</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<link rel="stylesheet" type="text/css" href="../../R.css">
</head><body>

<table width="100%" summary="page for knn1 {class}"><tr><td>knn1 {class}</td><td align="right">R Documentation</td></tr></table>
<h2>1-nearest neighbour classification</h2>


<h3>Description</h3>

<p>
Nearest neighbour classification for test set from training set. For
each row of the test set, the nearest (by Euclidean distance) training
set vector is found, and its classification used. If there is more than
one nearest, a majority vote is used with ties broken at random.
</p>


<h3>Usage</h3>

<pre>
knn1(train, test, cl)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>train</code></td>
<td>
matrix or data frame of training set cases.
</td></tr>
<tr valign="top"><td><code>test</code></td>
<td>
matrix or data frame of test set cases. A vector will be interpreted
as a row vector for a single case.
</td></tr>
<tr valign="top"><td><code>cl</code></td>
<td>
factor of true classification of training set.
</td></tr>
</table>

<h3>Value</h3>

<p>
factor of classifications of test set.</p>

<h3>References</h3>

<p>
Ripley, B. D. (1996)
<EM>Pattern Recognition and Neural Networks.</EM> Cambridge.
</p>
<p>
Venables, W. N. and Ripley, B. D. (2002)
<EM>Modern Applied Statistics with S.</EM> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p>
<code><a href="knn.html">knn</a></code>
</p>


<h3>Examples</h3>

<pre>
data(iris3)
train &lt;- rbind(iris3[1:25,,1], iris3[1:25,,2], iris3[1:25,,3])
test &lt;- rbind(iris3[26:50,,1], iris3[26:50,,2], iris3[26:50,,3])
cl &lt;- factor(c(rep("s",25), rep("c",25), rep("v",25)))
knn1(train, test, cl)
</pre>



<hr><div align="center">[Package <em>class</em> version 7.2-14 <a href="00Index.html">Index]</a></div>

</body></html>
