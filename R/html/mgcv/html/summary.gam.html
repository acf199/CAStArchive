<html><head><title>R: Summary for a GAM fit</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<link rel="stylesheet" type="text/css" href="../../R.css">
</head><body>

<table width="100%" summary="page for summary.gam {mgcv}"><tr><td>summary.gam {mgcv}</td><td align="right">R Documentation</td></tr></table>
<h2>Summary for a GAM fit</h2>


<h3>Description</h3>

<p>
Takes a fitted <code>gam</code> object produced by <code>gam()</code> and produces various useful
summaries from it.
</p>


<h3>Usage</h3>

<pre>
summary.gam(object,freq=TRUE,...)
print.summary.gam(x,...)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>object</code></td>
<td>
a fitted <code>gam</code> object as produced by <code>gam()</code>.</td></tr>
<tr valign="top"><td><code>x</code></td>
<td>
a <code>summary.gam</code> object produced by <code>summary.gam()</code>.</td></tr>
<tr valign="top"><td><code>freq</code></td>
<td>
By default p-values for individual terms are calculated using the frequentist estimated
covariance matrix of the parameter estimators. If this is set to FALSE then
the Bayesian covariance matrix of the parameters is used instead. See details. </td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
other arguments.</td></tr>
</table>

<h3>Details</h3>

<p>
Model degrees of freedom are taken as the trace of the influence (or
hat) matrix <i>A</i> for the model fit.
Residual degrees of freedom are taken as number of data minus model degrees of
freedom. 
Let <i>P_i</i> be the matrix 
giving the parameters of the ith smooth when applied to the data (or pseudodata in the generalized case) and let <i>X</i> 
be the design matrix of the model. Then <i>tr(XP_i)</i> is the edf for the ith term. Clearly this definition causes 
the edf's to add up properly! 
</p>
<p>
<code>print.summary.gam</code> tries to print various bits of summary information useful for term selection in a pretty way.
</p>
<p>
If <code>freq=FALSE</code> then the Bayesian parameter covariance matrix,
<code>object$Vp</code>, is used to calculate test statistics for terms, and the
degrees of freedom for reference distributions is taken as the estimated
degrees of freedom for the term concerned. This is not easy to justify
theoretically, and the resulting `Bayesian p-values' are difficult to
interpret and often have much worse frequentist performance than the default p-values.
</p>


<h3>Value</h3>

<p>
<code>summary.gam</code> produces a list of summary information for a fitted <code>gam</code> object. 
</p>
<table summary="R argblock">
<tr valign="top"><td><code>p.coeff</code></td>
<td>
is an array of estimates of the strictly parametric model coefficients.</td></tr>
<tr valign="top"><td><code>p.t</code></td>
<td>
is an array of the <code>p.coeff</code>'s divided by their standard errors.</td></tr>
<tr valign="top"><td><code>p.pv</code></td>
<td>
is an array of p-values for the null hypothesis that the corresponding parameter is zero. 
Calculated with reference to the t distribution with the estimated residual degrees of freedom for the model fit.</td></tr>
<tr valign="top"><td><code>m</code></td>
<td>
The number of smooth terms in the model.</td></tr>
<tr valign="top"><td><code>chi.sq</code></td>
<td>
An array of test statistics for assessing the significance of
model smooth terms. If <i>p_i</i> 
is the parameter vector for the ith smooth term, and this term has estimated
covariance matrix <i>V_i</i> then the 
statistic is <i>p_i'V_i^{k-}p_i</i>, where <i>V_i^{k-}</i> is the rank k 
pseudo-inverse of <i>V_i</i>, and k is estimated rank of  <i>V_i</i>.</td></tr>
<tr valign="top"><td><code>s.pv</code></td>
<td>
An array of approximate p-values for the null hypotheses that each
smooth term is zero. Be warned, these are only approximate. In the case in
which UBRE has been used, they are obtained by comparing the chi.sq statistic given above to the 
chi-squared distribution with k degrees of freedom, where k is the estimated
rank of  <i>V_i</i>. In the GCV case (in 
which the scale parameter will have been estimated) the statistic is compared
to an F distribution with k upper d.f.  and lower d.f. given by the residual degrees of freedom for the model . 
Typically the p-values will be somewhat too low, because they are conditional
on the smoothing parameters, which are usually uncertain. 
</td></tr>
<tr valign="top"><td><code>se</code></td>
<td>
array of standard error estimates for all parameter estimates.</td></tr>
<tr valign="top"><td><code>r.sq</code></td>
<td>
The adjusted r-squared for the model. Defined as the proportion of variance explained, where original variance and 
residual variance are both estimated using unbiased estimators. This quantity can be negative if your model is worse than a one 
parameter constant model, and can be higher for the smaller of two nested models! Note that proportion null deviance 
explained is probably more appropriate for non-normal errors.</td></tr>
<tr valign="top"><td><code>dev.expl</code></td>
<td>
The proportion of the null deviance explained by the model.</td></tr>
<tr valign="top"><td><code>edf</code></td>
<td>
array of estimated degrees of freedom for the model terms.</td></tr>
<tr valign="top"><td><code>residual.df</code></td>
<td>
estimated residual degrees of freedom.</td></tr>
<tr valign="top"><td><code>n</code></td>
<td>
number of data.</td></tr>
<tr valign="top"><td><code>gcv</code></td>
<td>
minimized GCV score for the model, if GCV used.</td></tr>
<tr valign="top"><td><code>ubre</code></td>
<td>
minimized UBRE score for the model, if UBRE used.</td></tr>
<tr valign="top"><td><code>scale</code></td>
<td>
estimated (or given) scale parameter.</td></tr>
<tr valign="top"><td><code>family</code></td>
<td>
the family used.</td></tr>
<tr valign="top"><td><code>formula</code></td>
<td>
the original GAM formula.</td></tr>
<tr valign="top"><td><code>dispersion</code></td>
<td>
the scale parameter.</td></tr>
<tr valign="top"><td><code>pTerms.df</code></td>
<td>
the degrees of freedom associated with each parameteric term
(excluding the constant).</td></tr>
<tr valign="top"><td><code>pTerms.chi.sq</code></td>
<td>
a Wald statistic for testing the null hypothesis that the
each parametric term is zero.</td></tr>
<tr valign="top"><td><code>pTerms.pv</code></td>
<td>
p-values associated with the tests that each term is
zero. For penalized fits these are approximate, being conditional on the smoothing
parameters. The reference distribution is an appropriate chi-squared when the
scale parameter is known, and is based on an F when it is not.</td></tr>
</table>

<h3>WARNING</h3>

<p>
The supplied p-values will often be underestimates if
smoothing parameters have been estimated as part of model fitting.
</p>


<h3>Author(s)</h3>

<p>
Simon N. Wood <a href="mailto:simon.wood@r-project.org">simon.wood@r-project.org</a>
</p>


<h3>References</h3>

<p>
Gu and Wahba (1991) Minimizing GCV/GML scores with multiple smoothing parameters via
the Newton method. SIAM J. Sci. Statist. Comput. 12:383-398
</p>
<p>
Wood, S.N. (2000)  Modelling and Smoothing Parameter Estimation
with Multiple  Quadratic Penalties. J.R.Statist.Soc.B 62(2):413-428
</p>
<p>
Wood, S.N. (2003) Thin plate regression splines. J.R.Statist.Soc.B 65(1):95-114
</p>
<p>
Wood, S.N. (2004a) Stable and efficient multiple smoothing parameter estimation for
generalized additive models. J. Amer. Statist. Ass.
</p>
<p>
Wood, S.N. (2004b) On confidence intervals for GAMs based on penalized
regression splines. Technical Report 04-12 Department of Statistics,
University of Glasgow.
</p>
<p>
<a href="http://www.stats.gla.ac.uk/~simon/">http://www.stats.gla.ac.uk/~simon/</a>
</p>


<h3>See Also</h3>

<p>
<code><a href="gam.html">gam</a></code>, <code><a href="predict.gam.html">predict.gam</a></code>,
<code><a href="gam.check.html">gam.check</a></code>, <code><a href="anova.gam.html">anova.gam</a></code>
</p>


<h3>Examples</h3>

<pre>
library(mgcv)
set.seed(0)
n&lt;-200
sig2&lt;-4
x0 &lt;- runif(n, 0, 1)
x1 &lt;- runif(n, 0, 1)
x2 &lt;- runif(n, 0, 1)
x3 &lt;- runif(n, 0, 1)
pi &lt;- asin(1) * 2
y &lt;- 2 * sin(pi * x0)
y &lt;- y + exp(2 * x1) - 3.75887
y &lt;- y + 0.2 * x2^11 * (10 * (1 - x2))^6 + 10 * (10 * x2)^3 * (1 - x2)^10 - 1.396
e &lt;- rnorm(n, 0, sqrt(abs(sig2)))
y &lt;- y + e
b&lt;-gam(y~s(x0)+s(x1)+s(x2)+s(x3))
plot(b,pages=1)
summary(b)
# now check the p-values by using a pure regression spline.....
b.d&lt;-round(b$edf)+1 
b.d&lt;-pmax(b.d,3) # can't have basis dimension less than this!
bc&lt;-gam(y~s(x0,k=b.d[1],fx=TRUE)+s(x1,k=b.d[2],fx=TRUE)+
        s(x2,k=b.d[3],fx=TRUE)+s(x3,k=b.d[4],fx=TRUE))
plot(bc,pages=1)
summary(bc)
# p-value check - increase k to make this useful!
n&lt;-200;p&lt;-0;k&lt;-20
for (i in 1:k)
{ b&lt;-gam(y~s(x,z),data=data.frame(y=rnorm(n),x=runif(n),z=runif(n)))
  p[i]&lt;-summary(b)$s.p[1]
}
plot(((1:k)-0.5)/k,sort(p))
</pre>



<hr><div align="center">[Package <em>mgcv</em> version 1.2-3 <a href="00Index.html">Index]</a></div>

</body></html>
